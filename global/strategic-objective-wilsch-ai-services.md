---
publish: true
---

# Strategic Objective - Wilsch AI Services

[[life-vision]]

The Strategic Objective defines what the business must do to achieve the Primary Aim. Framework: Michael Gerber, *The E-Myth Revisited*, Chapter 13.

---

## The Primary Aim (Summary)

A life lived in conscious system. Finding unknowns, exploring them, building them into systems, handing them off to operators, resting, learning from their use, and beginning again.

**First Cycle Deadline:** End of February 2027

**Financial Target:** €360,000 principal in interest-bearing assets at 10% → €3,000/month → freedom to do cycles without financial pressure

Full document: [Primary Aim - Life Vision](https://mariuswilsch.github.io/public-wilsch-ai-pages/global/primary-aim-life-vision)

---

## What the Business Must Do

**The business is a vehicle, not a destination.**

Wilsch AI Services exists to:
1. Generate revenue (to fund the €360k principal for freedom)
2. Provide friction and stakes (something real to work on)
3. Create handoff opportunities (people to receive systems)

The business itself is interchangeable. What matters: it serves as a reliable mechanism for running cycles.

---

## The Proprietary Operating System

**What we sell (commodity):** Finished AI projects—local deployment, legal automation, whatever the client needs.

**What clients walk away with (product):** Possibility space made tangible. Clients know they have problems but have no idea whether or how AI could solve them. The product is opening that possibility space—showing what's technically feasible before they even think about AI. Translating between business problems and AI capabilities. Making abstract potentials concrete.

**What makes it possible (proprietary method):** The Claude Code Operating System—an internal methodology for producing deterministically correct AI behavior. Clients don't see or learn this system. They experience the result: reliable delivery that proves the possibility space is real.

### The System Components (Handoff Sequence)

**1. Issue Lifecycle Router** — Design doc → finished product execution

**2. Improvement Loop** — Programming wrong AI behavior → deterministically right

**3. Knowledge Extraction (Phase 0)** — Meeting → transcript → design doc → uncertainties? → repeat until design doc complete → create issues

**Test for Alignment:** "Does this make the system run without me?"

**Extended Test:** "Can he improve the behavior of the system without me?"

---

## For Whom (The Customer)

### Central Demographic Model

**German Mittelstand** — the enterprise middle layer.

| Characteristic | Description |
|----------------|-------------|
| **Industries** | Law firms, building/facility management, industrial manufacturing, construction |
| **Company size** | Enterprise level — enough complexity to need AI, enough structure to implement |
| **NOT** | Marketing agencies, generative companies, small businesses, startups |

### Psychographic (Why They Buy)

> "AI is a color they've never seen — they can't imagine what it could do for them."

**The frustration:** Management pushes "focus on AI" but can't answer "why" or "where." The middle layer (ops/IT lead) is pressured to act but has no clear direction. AI is everywhere in the news, nowhere in their understanding.

**The product:** Make the possible visible — before they invest. Show them the color they've never seen.

**The relief:** Finally, something concrete to propose upward. Finally, an answer to "what should we do with AI?"

**The buyer:** Middle layer (operations lead, IT lead, department head) who needs to translate vague "AI!" mandates into actionable proposals. C-suite approves budget, but middle layer finds and evaluates you.

### Territory

| Element | Current State |
|---------|---------------|
| **Geographic** | Europe/DACH region |
| **Sales channel** | In-person only (no digital funnel) |
| **Expansion path** | Digital sales channel would expand territory |

---

## Standards

How we operate. What we promise. What we will never compromise.

### Integrity Standards

| Standard | Description |
|----------|-------------|
| **Data sovereignty** | Client data stays under their control. On-premise possible. German/EU data centers for cloud. |
| **Honesty over sale** | Will tell a client "AI won't help here" even if it loses the deal. No overselling. |

### Process Standards

| Standard | Description |
|----------|-------------|
| **Pflichtenheft before POC** | Specification document before any code is written. Always. No exceptions. |
| **Workshop → Spec → Build** | Free scoping (Workshop 1) → paid requirements (Workshop 2) → Pflichtenheft → POC |

### Quality Standards

| Standard | Description |
|----------|-------------|
| **Evaluation-based** | Build test infrastructure first. Define success metrics in the eval. AI measures against it. |
| **Project-specific metrics** | Each engagement defines its own success thresholds in the Pflichtenheft |

**Competitive differentiator:** Most AI vendors say "it works." We say "here's the eval, watch it pass."

---

## Exit Criteria (First Cycle Complete)

Any of these paths completes the first cycle:

| Path | Target | What It Proves |
|------|--------|----------------|
| **Revenue machine** | €360k accumulated through client projects | Operators can execute; model scales |
| **Sellable asset** | Business worth ~€360k | System works independently; buyer confidence |
| **OS product launched** | Product generates €360k | Methodology is packageable and valuable |

**Key insight:** The path doesn't matter. What matters is reaching €360k principal through a system that runs without the founder.

---

## The Operator Model

### Profile

| Requirement | Description |
|-------------|-------------|
| **Thinks like a software engineer** | Can architect systems, not just write code |
| **Has will** | Interested in building, wants to do it |
| **Junior or mid-level dev** | Follows documented processes, learns through repetition |

**Phase 1 Mindset:** Use the system to trial-and-error extremely quickly. Learn on the job. The system makes feedback loops fast — your job is to iterate, not to already know.

### How Learning Works (Core Requirement)

**If you don't get this, you will not succeed with the system.**

The Claude Code Operating System doesn't teach you — it makes trial and error so fast that you learn any concept you need on the job. AI concepts, Git, debugging, architecture, whatever comes up. But YOU must drive the learning. If the operator cannot learn independently through the system, the entire handoff fails — the founder becomes the bottleneck again because they have to teach you concepts.

**How everyone learns:** Try something → doesn't work → try again → works → learned something. This is universal. The question isn't whether to eliminate trial and error (you can't), but how to minimize cycle time.

**What the system does:** Makes feedback loops extremely fast. Code either runs or doesn't. Behavior is correct or isn't. Output meets requirements or doesn't. Each cycle takes minutes, not days.

**What the system does NOT do:** Teach you. The system won't respond to "help me learn this." You must be in the driver's seat — "I want to try this," "I want to learn this." The system executes what you want extremely quickly. That's why "has will" is a requirement.

**Asking questions is allowed.** You can ask the founder "how would you do this?" But even the founder's knowledge becomes stale if they haven't done something recently. The system (trial and error) is always the ultimate source of truth — for everyone.

**Two types of learning (taught in sequence):**

1. **Learning to deliver** — Concepts needed to complete projects. This is Phase 1 (Issue Lifecycle Router).

2. **Learning to improve** — How to program AI behavior, fix wrong behavior. This is Phase 2 (Improvement Loop). Taught after Phase 1 is solid.

**What this means for operators:**
- No prior knowledge required (AI, specific tools, frameworks, etc.)
- You learn concepts when you hit an issue that needs them
- The fast feedback loop means you learn quickly
- Requiring expertise upfront would create a bottleneck

**The distinction:**
- AI **behavior** should be deterministically correct (the system ensures this)
- AI **output** will have errors (expected, like any developer's code)

Your job is not to already know. Your job is to iterate.

### Training Method

| Element | Description |
|---------|-------------|
| **Mode** | Google Meet together, camera off, voice off by default |
| **Interaction** | Operator unmutes/shares screen when questions arise |
| **Grooming** | Daily sync (15-30 min) — review designs before implementation, discuss failed implementations |
| **Duration** | As many issues as needed until fully independent |
| **Hard cap** | 25 issues — should get it by 10, but 25 max before exit |
| **Principle** | Teaching is more important than founder focus during training period |

**Why grooming matters:** Cheap to change a design doc, expensive to change implementation. Daily checkpoint catches issues early. Also the structured moment for discussing failures — which is where learning happens.

### Handoff Sequence

```
Phase 1: Issue Lifecycle Router
  └─ Operator owns: design doc → finished product
  └─ Founder owns: Phase 0 (knowledge extraction) + system improvement
       ↓
Phase 2: Improvement Loop
  └─ Operator owns: flagging friction + fixing AI behavior
  └─ Founder owns: Phase 0 only
       ↓
Phase 3: Full Independence
  └─ Operator owns: execution + improvement
  └─ Founder owns: client relationships + next cycle
```

---

## Immediate Milestone

**Mohamed operates the full Issue Lifecycle Router.**

| What | Description |
|------|-------------|
| **Input** | Design doc (output of Knowledge Extraction loop) |
| **Process** | Full Issue Lifecycle: Creation → Design → Execution → Review → Closing |
| **Output** | Finished product deployed to production |
| **Founder role** | Available on Google Meet, but doesn't touch anything |

**Success criteria:** Mohamed can take a design doc and deliver a finished product without founder intervention.

**Why full cycle matters:** Just giving spec-implement issues doesn't work — the operator never learns the full cycle, never has to figure things out on the job. The core requirement (learning through the system) can't be met with partial handoff.

**Expected trajectory:** Operator will be slower at first. That time is learning. They'll get fast quickly because they don't have to build the system, just operate it.

**Why this matters:** If Mohamed works, the model is proven. A second operator can be trained the same way. The constraint (founder as bottleneck) is removed.

---

## What the Founder Works ON (Not IN)

Once Issue Lifecycle Router is handed off, founder time goes to:

**Knowledge Extraction (until handed off):**
- Scheduling client meetings
- Creating design docs from Knowledge Extraction loop

**Scaling:**
- Training new operators
- Building out systems for future phase handoffs

**Exit path activities:**
- Building asset worth ~€360k (sellable business)
- Building out the OS product (productized methodology)

**No longer doing:**
- ~~Executing issues~~ (handed off)

---

## Related Documents

- [Primary Aim - Life Vision](https://mariuswilsch.github.io/public-wilsch-ai-pages/global/primary-aim-life-vision)
- [Issue Lifecycle Router](https://mariuswilsch.github.io/public-wilsch-ai-pages/global/issue-lifecycle-router)
- [Three-Session Model](https://mariuswilsch.github.io/public-wilsch-ai-pages/global/three-session-model)
- [Ship with Confidence](https://mariuswilsch.github.io/public-wilsch-ai-pages/global/ship-with-confidence)

---

## Source

- E-Myth Strategic Objective interview (2026-02-03)
- E-Myth Strategic Objective completion session (2026-02-04) — added For Whom, Territory, Standards
- Framework: Michael Gerber, *The E-Myth Revisited*, Chapter 13
