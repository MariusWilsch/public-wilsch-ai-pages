---
publish: true
---

# Lokale KI-Entwicklung â€” Design Doc
[[client-wilsch-group]]

Design Doc fÃ¼r eine lokale KI-EntwicklungskapazitÃ¤t: Hardware, Modelle, rechtlicher Rahmen und kommerzielles Angebot fÃ¼r datensensible Kunden.

---

## Problemstellung

Wir nutzen Cloud-basierte KI (Claude von Anthropic) fÃ¼r unsere gesamte Kundenentwicklung â€” sowohl fÃ¼r das LÃ¶sungsdesign als auch fÃ¼r die Code-Implementierung. Das funktioniert fÃ¼r die meisten Kunden. Einige Kunden kÃ¶nnen jedoch nicht akzeptieren, dass ihre Daten von externen Cloud-Diensten verarbeitet werden â€” sei es aufgrund von DatensouverÃ¤nitÃ¤t, regulatorischen Anforderungen (DSGVO, BaFin, KRITIS) oder internen Sicherheitsrichtlinien, die das Senden von Daten an US-Anbieter grundsÃ¤tzlich untersagen.

Wichtig: Anonymisierte Daten (echte Schemastruktur, synthetische Werte) sind fÃ¼r die KI genauso effektiv wie Echtdaten. Claude versteht die Datenstruktur, ohne echte KundendatensÃ¤tze zu sehen. Das eigentliche Problem entsteht erst, wenn ein Kunde nicht einmal anonymisierte Schemata in die Cloud senden will â€” dann verliert die KI jeglichen Kontext Ã¼ber die Datenstruktur und kann nicht effektiv arbeiten.

Heute fehlt uns eine glaubwÃ¼rdige lokale Alternative fÃ¼r genau diese Kunden. Ohne eine solche Alternative verlieren wir AuftrÃ¤ge, bei denen DatensensibilitÃ¤t nicht verhandelbar ist.

**Voraussetzungen:**
- Open-Source-Frontier-Modelle (Qwen3.5-397B, GLM-5, Kimi K2.5) erreichen mittlerweile Claude Code 4.5 (Sonnet/Opus)-QualitÃ¤t fÃ¼r Code-Implementierungsaufgaben
- Consumer-Hardware (Mac Studio 512GB) kann diese Modelle in produktionsreifer PrÃ¤zision (FP8) fÃ¼r unter 10.000â‚¬ betreiben
- Mindestens ein aktiver Kundenprospekt hat DatensensibilitÃ¤tsanforderungen, die Anthropics Standard-DPA nicht vollstÃ¤ndig abdecken kann

---

## Erfolgsdefinition

| Element | Definition |
|---------|-----------|
| **Ziel** | Ein Drei-Stufen-Angebot, das jeden Kunden bedienen kann â€” unabhÃ¤ngig von dessen Datenanforderungen |
| **Erfolg** | Thomas und Ulrich kÃ¶nnen in KundengesprÃ¤chen die Frage â€Wie gehen Sie mit unseren Daten um?" konkret und glaubwÃ¼rdig beantworten |
| **Done-Test** | KÃ¶nnen wir fÃ¼r alle drei Stufen (Cloud, Hybrid, Voll-Lokal) Hardware, Modell und rechtlichen Rahmen benennen? â†’ Wenn ja â†’ technische Grundlage steht |

---

## Ansatz

### 1. Drei-Stufen-Modell

Unser Angebot gliedert sich in drei Stufen, je nach Datenanforderung des Kunden:

| Stufe | Kundensituation | Wie wir arbeiten | Lokale Hardware nÃ¶tig? |
|-------|----------------|------------------|----------------------|
| **Stufe 1: Cloud (DPA)** | Kunde unterzeichnet DPA, akzeptiert Anthropics Bedingungen | Claude Ã¼bernimmt alles â€” Design und Implementierung | Nein |
| **Stufe 2: Hybrid** | Anonymisierte Schemata OK, echte Daten mÃ¼ssen lokal bleiben | Claude designt mit anonymisierten Daten, lokales Modell implementiert mit echten Daten | Ja |
| **Stufe 3: Voll-Lokal** | Keine Daten dÃ¼rfen in die Cloud | Lokales Modell Ã¼bernimmt Design und Implementierung | Ja |

**Wie das in der Praxis funktioniert:**

- **Phase 1 â€” Design:** Marius entwirft die technische LÃ¶sung mit Claude (Cloud-KI). Bei Stufe 2 sieht Claude nur anonymisierte Datenstrukturen (echte Tabellennamen und Spalten, synthetische Werte). Bei Stufe 3 arbeitet Claude ohne Kundendaten.
- **Phase 2 â€” Implementierung:** Ein lokales KI-Modell auf unserem Mac Studio implementiert den Code gegen die echten Kundendaten. Keine Daten verlassen unsere Maschine.

**USP:** *Wir designen mit der besten KI der Welt. Wir implementieren mit euren Daten auf unserer lokalen Infrastruktur.*

Die DPA (Datenverarbeitungsvereinbarung) bestimmt, welche Stufe ein Kunde benÃ¶tigt. Eine gute DPA ermÃ¶glicht Stufe 1 â€” die einfachste und qualitativ beste Variante. Lokale Hardware ist die RÃ¼ckfalloption fÃ¼r Kunden, die Stufe 1 nicht akzeptieren kÃ¶nnen.

### 2. Modellauswahl

**Aktueller Stand (Februar 2026):** Vier Frontier-Open-Source-Modelle wurden evaluiert:

| Modell | Parameter | Aktive Parameter | FP8-Speicherbedarf | Passt auf 512GB? | Lizenz |
|--------|-----------|-----------------|-------------------|-----------------|--------|
| **[Qwen3.5-397B](https://huggingface.co/Qwen/Qwen3.5-397B-A17B)** | 397 Mrd. (MoE) | 17 Mrd. | ~397 GB | âœ… Ja | [Apache 2.0](https://huggingface.co/Qwen/Qwen3.5-397B-A17B) â€” kommerziell uneingeschrÃ¤nkt |
| **[MiniMax M2.5](https://huggingface.co/MiniMaxAI/MiniMax-M2.5)** | 229 Mrd. (MoE) | 10 Mrd. | ~229 GB | âœ… Ja | [Modified MIT](https://github.com/MiniMax-AI/MiniMax-M2.5/blob/main/LICENSE) â€” kommerziell frei |
| **[GLM-5](https://huggingface.co/zai-org/GLM-5)** | 744 Mrd. (MoE) | 40 Mrd. | ~744 GB | âŒ Nein | [MIT](https://glm5.net/) â€” kommerziell uneingeschrÃ¤nkt |
| **[Kimi K2.5](https://huggingface.co/moonshotai/Kimi-K2.5)** | 1 Bio. (MoE) | 32 Mrd. | ~600+ GB | âŒ Nein | [Modified MIT](https://github.com/MoonshotAI/Kimi-K2.5/blob/master/LICENSE) â€” kommerziell frei unter 100M MAU |

**Ergebnis:** Qwen3.5-397B und MiniMax M2.5 sind die beiden Frontier-Modelle, die bei FP8-PrÃ¤zision auf einer einzelnen Maschine (512GB) laufen. M2.5 ist auf Softwareentwicklung spezialisiert (80,2% SWE-Bench Verified), Qwen3.5 ist das stÃ¤rkere Allzweckmodell. GLM-5 und Kimi K2.5 erfordern Multi-Maschinen-Clustering via [EXO](https://github.com/exo-explore/exo).

**QualitÃ¤tsstandard:**
- **FP8 ist das Minimum** fÃ¼r produktive Kundenarbeit (nahezu verlustfrei, >95% QualitÃ¤t)
- **4-Bit-Quantisierung** (FP4, NF4, INT4) gilt als experimentell â€” nur fÃ¼r interne Tests
- Apple-Silicon-optimierte Variante: [Qwen3.5-397B MLX 4-bit](https://huggingface.co/mlx-community/Qwen3.5-397B-A17B-4bit)

**Monitoring:** Marius Ã¼berwacht laufend, welche Frontier-Modelle bei FP8 auf einer einzelnen, voll ausgestatteten Maschine (512GB, <10.000â‚¬) laufen. Die Modelllandschaft verÃ¤ndert sich wÃ¶chentlich â€” Qwen3.5 wurde am 16. Februar 2026 verÃ¶ffentlicht, GLM-5 fÃ¼nf Tage zuvor.

### 3. Hardware-Infrastruktur

**Entscheidung:** Wir kaufen einen Mac Studio als interne Entwicklungsinfrastruktur. Keine Kunden-Hardware â€” unsere Maschine, unsere Kontrolle. â€Voll lokal" bedeutet: Das Modell lÃ¤uft auf diesem Mac Studio, Kundendaten verlassen diese Maschine nicht.

**Kaufplan:**
1. **Sofort:** Mac Studio M3 Ultra (512GB, ~9.500â‚¬) â€” verfÃ¼gbar, deckt aktiven Bedarf
2. **FrÃ¼hjahr 2026:** Upgrade auf Mac Studio M5 Ultra (512GB, ~1.100 GB/s Bandbreite)

**Hardware-Vergleich:**

| System | GPU-Speicher | Bandbreite | Preis | Qwen3.5 FP8? | Formfaktor |
|--------|-------------|-----------|-------|--------------|------------|
| **[Mac Studio M3 Ultra](https://www.apple.com/mac-studio/specs/)** | 512GB unified | 819 GB/s | ~9.500â‚¬ | âœ… | Desktop |
| **[Mac Studio M5 Ultra](https://www.macworld.com/article/2973459/2026-mac-studio-what-we-know-about-the-upcoming-m5-update.html)** *(erwartet)* | 512GB unified | ~1.100 GB/s | ~9.000â‚¬ | âœ… | Desktop |
| **[Tinybox Red v2](https://tinycorp.myshopify.com/products/tinybox-red-v2)** | 144GB diskret (6Ã— 7900XTX) | ~1 TB/s | ~12.000â‚¬ | âœ… | 12U Rack |
| **[NVIDIA DGX Spark](https://www.nvidia.com/en-us/products/workstations/dgx-spark/)** | 128GB unified | 273 GB/s | ~4.000â‚¬ | âœ… | Desktop |

**Warum Mac Studio:** 512GB Unified Memory (3,5Ã— mehr als Tinybox), Desktop-Formfaktor, ~100W Stromverbrauch (vs. 3.200W bei Tinybox), Betriebssystemintegration fÃ¼r Entwicklungsworkflows. HÃ¶chste SpeicherkapazitÃ¤t im Budget unter 10.000â‚¬.

**Skalierungsoption:** [EXO](https://github.com/exo-explore/exo) (kostenlos, Open Source) ermÃ¶glicht es, mehrere Maschinen zu einem Cluster zu verbinden â€” fÃ¼r zukÃ¼nftige Modelle, die >512GB bei FP8 benÃ¶tigen. Thunderbolt 5 am Mac Studio ist eine Voraussetzung fÃ¼r effizientes Clustering. Aktuell nicht benÃ¶tigt â€” eine Einzelmaschine reicht fÃ¼r Qwen3.5-397B. FÃ¼r GLM-5 (744B) oder Kimi K2.5 (1T) wÃ¤re EXO-Clustering mit einer zweiten Maschine erforderlich.

### 4. Rechtlicher Rahmen

Anthropic (der Hersteller von Claude) bietet zwei verschiedene Produkte mit **grundlegend unterschiedlichen Datenschutzbedingungen**. FÃ¼r die Bewertung ist es entscheidend, diese Unterscheidung zu verstehen.

> **Legende:**
>
> ğŸ¢ **Commercial** = Anthropic API â€” das Produkt fÃ¼r Unternehmen. Wir nutzen dies fÃ¼r Kundenarbeit. Anthropic ist hier Auftragsverarbeiter, der Kunde bleibt Datenverantwortlicher. Anthropic stellt eine eigene [DPA (Datenverarbeitungsvereinbarung)](https://www.anthropic.com/legal/data-processing-addendum) bereit, die automatisch gilt â€” keine separate Verhandlung nÃ¶tig.
>
> ğŸ‘¤ **Consumer** = claude.ai â€” das Produkt fÃ¼r Endverbraucher. Anthropic ist hier selbst Datenverantwortlicher. Keine DPA, andere Regeln. **Darf nicht fÃ¼r Kundenarbeit verwendet werden.**

#### Was Anthropic zusichert (Stand Februar 2026)

**Training auf Daten:**
- ğŸ¢ Commercial: Kein Training auf Kundendaten â€” vertraglich verboten ([Commercial Terms Â§B](https://www.anthropic.com/legal/commercial-terms))
- ğŸ‘¤ Consumer: Training standardmÃ¤ÃŸig aktiv, Opt-out mÃ¶glich ([Privacy Policy](https://www.anthropic.com/legal/privacy))

**Datenspeicherung:**
- ğŸ¢ Commercial: 30 Tage, dann automatisch gelÃ¶scht ([Retention Policy](https://privacy.anthropic.com/en/articles/7996866-how-long-do-you-store-personal-data))
- ğŸ‘¤ Consumer: Solange Konto aktiv, LÃ¶schung erst auf Anfrage ([Consumer Retention](https://privacy.anthropic.com/en/articles/10023548-how-long-do-you-store-personal-data))

**DPA (Datenverarbeitungsvereinbarung):**
- ğŸ¢ Commercial: Anthropic stellt eigene DPA bereit, automatisch im Vertrag enthalten ([Anthropic DPA](https://www.anthropic.com/legal/data-processing-addendum))
- ğŸ‘¤ Consumer: Keine DPA â€” Anthropic ist selbst Verantwortlicher

**EU-Vertragspartner:**
- ğŸ¢ ğŸ‘¤ Beide: Anthropic Ireland, Limited ([Regional Compliance](https://claude.com/regional-compliance))

**Zertifizierungen:**
- ğŸ¢ ğŸ‘¤ Beide: SOC 2 Type 2, ISO 27001, ISO 27017, ISO 27018 ([Regional Compliance](https://claude.com/regional-compliance))

#### Bekannte Einwandspunkte fÃ¼r regulierte Kunden

Auch mit der Commercial API und Anthropics DPA bleiben folgende Punkte, die regulierte Kunden (BaFin, KRITIS, Gesundheitswesen) bemÃ¤ngeln kÃ¶nnen:

**Hohes Risiko:**
- ğŸ¢ ğŸ‘¤ **US CLOUD Act** â€” SCCs (Standardvertragsklauseln) schÃ¼tzen nicht vor US-BehÃ¶rdenzugriff auf Anthropic PBC als US-Muttergesellschaft
- ğŸ¢ **Keine EU-Datenresidenz garantiert** â€” die Standard-API routet global. EU-Verarbeitung nur Ã¼ber AWS Bedrock EU oder GCP Vertex EU mÃ¶glich (erfordert separate Konfiguration)
- ğŸ¢ ğŸ‘¤ **Vage â€harmful use"-LÃ¶schausnahme** â€” Anthropic darf Daten potenziell unbefristet speichern, wenn sie als schÃ¤dlich eingestuft werden

**Mittleres Risiko:**
- ğŸ¢ ğŸ‘¤ **Safety-Review** â€” wenn Anthropics Classifier Inhalte flaggt, kÃ¶nnen Daten bis zu 2 Jahre gespeichert werden, unabhÃ¤ngig von anderen LÃ¶schfristen
- ğŸ¢ **Sub-Processor-Liste** â€” nicht vertraglich fixiert, rollierend aktualisiert, nur 15 Tage Einspruchsfrist fÃ¼r neue Sub-Processors

**â†’ Kunden mit diesen EinwÃ¤nden werden auf Stufe 2/3 (lokale Inferenz) geleitet.**

#### Offene Aufgaben

**Undefined:** FÃ¼r Stufe 2/3 benÃ¶tigen wir eine eigene Wilsch AI DPA, die regelt, wie wir Kundendaten auf unserem Mac Studio handhaben. Separates Arbeitspaket, erfordert juristische PrÃ¼fung. â†’ [siehe Meeting-Agenda](https://mariuswilsch.github.io/public-wilsch-ai-pages/project/wilsch-group/local-ai-development-meeting-agenda)

**Undefined:** Preismodell fÃ¼r lokale Entwicklungsstufen â†’ [siehe Meeting-Agenda](https://mariuswilsch.github.io/public-wilsch-ai-pages/project/wilsch-group/local-ai-development-meeting-agenda)

---

## Quellen

- **Issue:** [#834: Evaluate Local AI Development Hardware & Offering](https://github.com/DaveX2001/deliverable-tracking/issues/834)
- **Org Chart:** [Organization Chart - Wilsch AI Services](https://mariuswilsch.github.io/public-wilsch-ai-pages/global/organization-chart-wilsch-ai-services)
- **Anthropic Terms:** [Commercial Terms](https://www.anthropic.com/legal/commercial-terms) | [DPA](https://www.anthropic.com/legal/data-processing-addendum) | [Regional Compliance](https://claude.com/regional-compliance)
- **EXO:** [github.com/exo-explore/exo](https://github.com/exo-explore/exo)
- **Qwen3.5:** [HuggingFace](https://huggingface.co/Qwen/Qwen3.5-397B-A17B) | [MLX 4-bit](https://huggingface.co/mlx-community/Qwen3.5-397B-A17B-4bit)
- **MiniMax M2.5:** [HuggingFace](https://huggingface.co/MiniMaxAI/MiniMax-M2.5)
- **Session:** ce7b3c88-8c2e-47cb-b165-daeae5aa8c10.jsonl
